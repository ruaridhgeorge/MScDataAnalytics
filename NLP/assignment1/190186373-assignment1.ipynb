{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [COM4513-6513] Assignment 1: Text Classification with Logistic Regression\n",
    "\n",
    "### Instructor: Nikos Aletras\n",
    "\n",
    "\n",
    "The goal of this assignment is to develop and test two text classification systems: \n",
    "\n",
    "- **Task 1:** sentiment analysis, in particular to predict the sentiment of movie review, i.e. positive or negative (binary classification).\n",
    "- **Task 2:** topic classification, to predict whether a news article is about International issues, Sports or Business (multiclass classification).\n",
    "\n",
    "\n",
    "For that purpose, you will implement:\n",
    "\n",
    "- Text processing methods for extracting Bag-Of-Word features, using (1) unigrams, bigrams and trigrams to obtain vector representations of documents. Two vector weighting schemes should be tested: (1) raw frequencies (**3 marks; 1 for each ngram type**); (2) tf.idf (**1 marks**). \n",
    "- Binary Logistic Regression classifiers that will be able to accurately classify movie reviews trained with (1) BOW-count (raw frequencies); and (2) BOW-tfidf (tf.idf weighted) for Task 1. \n",
    "- Multiclass Logistic Regression classifiers that will be able to accurately classify news articles trained with (1) BOW-count (raw frequencies); and (2) BOW-tfidf (tf.idf weighted) for Task 2. \n",
    "- The Stochastic Gradient Descent (SGD) algorithm to estimate the parameters of your Logistic Regression models. Your SGD algorithm should:\n",
    "    - Minimise the Binary Cross-entropy loss function for Task 1 (**3 marks**)\n",
    "    - Minimise the Categorical Cross-entropy loss function for Task 2 (**3 marks**)\n",
    "    - Use L2 regularisation (both tasks) (**1 mark**)\n",
    "    - Perform multiple passes (epochs) over the training data (**1 mark**)\n",
    "    - Randomise the order of training data after each pass (**1 mark**)\n",
    "    - Stop training if the difference between the current and previous validation loss is smaller than a threshold (**1 mark**)\n",
    "    - After each epoch print the training and development loss (**1 mark**)\n",
    "- Discuss how did you choose hyperparameters (e.g. learning rate and regularisation strength)?  (**2 marks; 0.5 for each model in each task**).\n",
    "- After training the LR models, plot the learning process (i.e. training and validation loss in each epoch) using a line plot (**1 mark; 0.5 for both BOW-count and BOW-tfidf LR models in each task**) and discuss if your model overfits/underfits/is about right.\n",
    "- Model interpretability by showing the most important features for each class (i.e. most positive/negative weights). Give the top 10 for each class and comment on whether they make sense (if they don't you might have a bug!).  If we were to apply the classifier we've learned into a different domain such laptop reviews or restaurant reviews, do you think these features would generalise well? Can you propose what features the classifier could pick up as important in the new domain? (**2 marks; 0.5 for BOW-count and BOW-tfidf LR models respectively in each task**)\n",
    "\n",
    "\n",
    "### Data - Task 1 \n",
    "\n",
    "The data you will use for Task 1 are taken from here: [http://www.cs.cornell.edu/people/pabo/movie-review-data/](http://www.cs.cornell.edu/people/pabo/movie-review-data/) and you can find it in the `./data_sentiment` folder in CSV format:\n",
    "\n",
    "- `data_sentiment/train.csv`: contains 1,400 reviews, 700 positive (label: 1) and 700 negative (label: 0) to be used for training.\n",
    "- `data_sentiment/dev.csv`: contains 200 reviews, 100 positive and 100 negative to be used for hyperparameter selection and monitoring the training process.\n",
    "- `data_sentiment/test.csv`: contains 400 reviews, 200 positive and 200 negative to be used for testing.\n",
    "\n",
    "### Data - Task 2\n",
    "\n",
    "The data you will use for Task 2 is a subset of the [AG News Corpus](http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html) and you can find it in the `./data_topic` folder in CSV format:\n",
    "\n",
    "- `data_topic/train.csv`: contains 2,400 news articles, 800 for each class to be used for training.\n",
    "- `data_topic/dev.csv`: contains 150 news articles, 50 for each class to be used for hyperparameter selection and monitoring the training process.\n",
    "- `data_topic/test.csv`: contains 900 news articles, 300 for each class to be used for testing.\n",
    "\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "You should submit a Jupyter Notebook file (assignment1.ipynb) and an exported PDF version (you can do it from Jupyter: `File->Download as->PDF via Latex`).\n",
    "\n",
    "You are advised to follow the code structure given in this notebook by completing all given funtions. You can also write any auxilliary/helper functions (and arguments for the functions) that you might need but note that you can provide a full solution without any such functions. Similarly, you can just use only the packages imported below but you are free to use any functionality from the [Python Standard Library](https://docs.python.org/2/library/index.html), NumPy, SciPy and Pandas. You are not allowed to use any third-party library such as Scikit-learn (apart from metric functions already provided), NLTK, Spacy, Keras etc..\n",
    "\n",
    "Please make sure to comment your code. You should also mention if you've used Windows (not recommended) to write and test your code. There is no single correct answer on what your accuracy should be, but correct implementations usually achieve F1-scores around 80\\% or higher. The quality of the analysis of the results is as important as the accuracy itself. \n",
    "\n",
    "This assignment will be marked out of 20. It is worth 20\\% of your final grade in the module.\n",
    "\n",
    "The deadline for this assignment is **23:59 on Fri, 20 Mar 2020** and it needs to be submitted via MOLE. Standard departmental penalties for lateness will be applied. We use a range of strategies to detect [unfair means](https://www.sheffield.ac.uk/ssid/unfair-means/index), including Turnitin which helps detect plagiarism, so make sure you do not plagiarise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw texts and labels into arrays\n",
    "\n",
    "First, you need to load the training, development and test sets from their corresponding CSV files (tip: you can use Pandas dataframes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:31:36.292691Z",
     "start_time": "2020-02-15T14:31:35.549108Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from math import log\n",
    "\n",
    "# fixing random seed for reproducibility\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:28.145788Z",
     "start_time": "2020-02-15T14:17:28.066100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Throughout the assignment, I will denote variables associated with 2\n",
    "# with 2 at the end of the variable name.\n",
    "\n",
    "# Task 1 data sets\n",
    "train_set1 = pd.read_csv('./data_sentiment/train.csv', header = None, names = ['text', 'label'])\n",
    "test_set1 = pd.read_csv('./data_sentiment/test.csv', header = None, names = ['text', 'label'])\n",
    "dev_set1 = pd.read_csv('./data_sentiment/dev.csv', header = None, names = ['text', 'label'])\n",
    "\n",
    "# Task 2 data sets\n",
    "train_set2 = pd.read_csv('./data_topic/train.csv', header = None, names = ['label', 'text'])\n",
    "test_set2 = pd.read_csv('./data_topic/test.csv', header = None, names = ['label', 'text'])\n",
    "dev_set2 = pd.read_csv('./data_topic/dev.csv', header = None, names = ['label', 'text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use Pandas you can see a sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>AP - Vice President Dick Cheney said Tuesday t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>Baghdad, Sept. 8 (NNN): Bloody clashes on Tues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>DUBAI/PARIS (Reuters) - The French government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>NEW YORK - Investors were unmoved by Federal R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>Bandar Seri Begawan - Bruneis Royal Wedding be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>LONDON, England -- Andrew Symonds rode his luc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>For most tennis players, having about the same...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>AP - It was the surest sign that the Kobe Brya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>AP - Drew Tate threw two touchdowns in his fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>Brian Kerr took his Ireland squad to the dogs ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                               text\n",
       "45      1  AP - Vice President Dick Cheney said Tuesday t...\n",
       "46      1  Baghdad, Sept. 8 (NNN): Bloody clashes on Tues...\n",
       "47      1   DUBAI/PARIS (Reuters) - The French government...\n",
       "48      1  NEW YORK - Investors were unmoved by Federal R...\n",
       "49      1  Bandar Seri Begawan - Bruneis Royal Wedding be...\n",
       "50      2  LONDON, England -- Andrew Symonds rode his luc...\n",
       "51      2  For most tennis players, having about the same...\n",
       "52      2  AP - It was the surest sign that the Kobe Brya...\n",
       "53      2  AP - Drew Tate threw two touchdowns in his fir...\n",
       "54      2  Brian Kerr took his Ireland squad to the dogs ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set2[45:55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to put the raw texts into Python lists and their corresponding labels into NumPy arrays:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:31.115577Z",
     "start_time": "2020-02-15T14:17:31.108038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Task 1 label array and raw text list definitions\n",
    "\n",
    "Y_tr = np.array(train_set1['label'])\n",
    "Y_test = np.array(test_set1['label'])\n",
    "Y_dev = np.array(dev_set1['label'])\n",
    "\n",
    "train_text1 = [text for text in train_set1['text']]\n",
    "test_text1 = [text for text in test_set1['text']]\n",
    "dev_text1 = [text for text in dev_set1['text']]\n",
    "\n",
    "# Task 2 label array and raw text list definitions\n",
    "\n",
    "Y_tr2 = np.array(train_set2['label'])\n",
    "Y_test2 = np.array(test_set2['label'])\n",
    "Y_dev2 = np.array(dev_set2['label'])\n",
    "\n",
    "train_text2 = [text for text in train_set2['text']]\n",
    "test_text2 = [text for text in test_set2['text']]\n",
    "dev_text2 = [text for text in dev_set2['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words Representation \n",
    "\n",
    "\n",
    "To train and test Logisitc Regression models, you first need to obtain vector representations for all documents given a vocabulary of features (unigrams, bigrams, trigrams).\n",
    "\n",
    "\n",
    "## Text Pre-Processing Pipeline\n",
    "\n",
    "To obtain a vocabulary of features, you should: \n",
    "- **tokenise** all texts into a list of unigrams (tip: using a regular expression) \n",
    "- remove **stop words** (using the one provided or one of your preference) \n",
    "- compute bigrams, trigrams given the remaining unigrams\n",
    "- **remove ngrams appearing in less than K documents**\n",
    "- use the remaining to create a vocabulary of unigrams, bigrams and trigrams (you can keep top N if you encounter memory issues).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:31.860420Z",
     "start_time": "2020-02-15T14:17:31.855439Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = ['a','in','on','at','and','or', \n",
    "              'to', 'the', 'of', 'an', 'by', \n",
    "              'as', 'is', 'was', 'were', 'been', 'be', \n",
    "              'are','for', 'this', 'that', 'these', 'those', 'you', 'i',\n",
    "             'it', 'he', 'she', 'we', 'they', 'will', 'have', 'has',\n",
    "              'do', 'did', 'can', 'could', 'who', 'which', 'what', \n",
    "             'his', 'her', 'they', 'them', 'from', 'with', 'its', 'is', 'The']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram extraction from a document\n",
    "\n",
    "You first need to implement the `extract_ngrams` function. It takes as input:\n",
    "- `x_raw`: a string corresponding to the raw text of a document\n",
    "- `ngram_range`: a tuple of two integers denoting the type of ngrams you want to extract, e.g. (1,2) denotes extracting unigrams and bigrams.\n",
    "- `token_pattern`: a string to be used within a regular expression to extract all tokens. Note that data is already tokenised so you could opt for a simple white space tokenisation.\n",
    "- `stop_words`: a list of stop words\n",
    "- `vocab`: a given vocabulary. It should be used to extract specific features.\n",
    "\n",
    "and returns:\n",
    "\n",
    "- a list of all extracted features.\n",
    "\n",
    "See the examples below to see how this function should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:33.169090Z",
     "start_time": "2020-02-15T14:17:33.161268Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract ngrams of one length n\n",
    "\n",
    "def ngrams(x_raw, n=3, token_pattern=r'\\b[A-Za-z][A-Za-z]+\\b', stop_words=[]):\n",
    "   \n",
    "    x_list = re.findall(token_pattern, x_raw)               \n",
    "    unigrams = [word for word in x_list if word not in stop_words]\n",
    "    ngrams = [tuple(unigrams[i:i+n]) for i in range(len(unigrams)-n+1)]\n",
    "    \n",
    "    return ngrams\n",
    "\n",
    "# Extract ngrams which uses previous function to get ngrams of all numbers up to n\n",
    "\n",
    "def extract_ngrams(x_raw, n=3, token_pattern=r'\\b[A-Za-z][A-Za-z]+\\b', stop_words=[], vocab=set()):\n",
    "    all_ngrams = []\n",
    "    for i in range(1, n+1):\n",
    "        ngrams_i = ngrams(x_raw, n=i, token_pattern=token_pattern, stop_words=stop_words)\n",
    "        for x in ngrams_i:\n",
    "            ngram = ' '.join(x)\n",
    "            all_ngrams.append(ngram)\n",
    "            \n",
    "    if vocab != set():\n",
    "        all_ngrams = vocab\n",
    "        \n",
    "    return all_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great', 'movie', 'watch', 'great movie', 'movie watch', 'great movie watch']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_ngrams(x_raw = \"this is a great movie to the watch the\", stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is OK to represent n-grams using lists instead of tuples: e.g. `['great', ['great', 'movie']]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocabulary of n-grams\n",
    "\n",
    "Then the `get_vocab` function will be used to (1) create a vocabulary of ngrams; (2) count the document frequencies of ngrams; (3) their raw frequency. It takes as input:\n",
    "- `X_raw`: a list of strings each corresponding to the raw text of a document\n",
    "- `ngram_range`: a tuple of two integers denoting the type of ngrams you want to extract, e.g. (1,2) denotes extracting unigrams and bigrams.\n",
    "- `token_pattern`: a string to be used within a regular expression to extract all tokens. Note that data is already tokenised so you could opt for a simple white space tokenisation.\n",
    "- `stop_words`: a list of stop words\n",
    "- `min_df`: keep ngrams with a minimum document frequency.\n",
    "- `keep_topN`: keep top-N more frequent ngrams.\n",
    "\n",
    "and returns:\n",
    "\n",
    "- `vocab`: a set of the n-grams that will be used as features.\n",
    "- `df`: a Counter (or dict) that contains ngrams as keys and their corresponding document frequency as values.\n",
    "- `ngram_counts`: counts of each ngram in vocab\n",
    "\n",
    "Hint: it should make use of the `extract_ngrams` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:35.821240Z",
     "start_time": "2020-02-15T14:17:35.814722Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vocab(X_raw, n=3, token_pattern=r'\\b[A-Za-z][A-Za-z]+\\b', min_df=0, keep_topN=0, stop_words=[]):\n",
    "    # Dictionaries for term frquency and document frequency\n",
    "    df = {}\n",
    "    tf = {}\n",
    "    for text in X_raw:\n",
    "        ngrams = extract_ngrams(text, n=n, token_pattern=token_pattern, stop_words=stop_words) # To populate tf\n",
    "        ngrams_unique = set(ngrams) # To populate df\n",
    "        \n",
    "        for ngram in ngrams_unique:\n",
    "            if ngram in df:\n",
    "                df[ngram] += 1\n",
    "            else:\n",
    "                df[ngram] = 1\n",
    "\n",
    "        for ngram in ngrams:\n",
    "            if ngram in tf:\n",
    "                tf[ngram] += 1\n",
    "            else:\n",
    "                tf[ngram] = 1\n",
    "    \n",
    "    \n",
    "    for ngram, count in df.items():\n",
    "        if count < min_df:\n",
    "            df.pop(ngram)\n",
    "            tf.pop(ngram)\n",
    "    \n",
    "    if keep_topN != 0:\n",
    "        #df = dict(Counter(df).most_common(keep_topN))\n",
    "        tf = dict(Counter(tf).most_common(keep_topN))\n",
    "    \n",
    "    for ngram in list(df.keys()):\n",
    "        if ngram not in tf.keys():\n",
    "            df.pop(ngram)\n",
    "    \n",
    "    vocab = set(tf.keys())\n",
    "    ngram_counts = list(tf.values())    \n",
    "    \n",
    "    return vocab, df, ngram_counts\n",
    "\n",
    "# list.sort() sorts any list of strings into alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function with small data.\n",
    "# X_raw = [\"great movie Ruaridh great movie\",\n",
    "#          \"have never watched is movie the\",\n",
    "#          \"today Ruaridh watched movie dinner today\"]\n",
    "\n",
    "# get_vocab(X_raw, keep_topN = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should use `get_vocab` to create your vocabulary and get document and raw frequencies of n-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:39.319793Z",
     "start_time": "2020-02-15T14:17:36.836545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "\n",
      "['tell', 'past', 'carrie', 'south', 'connected', 'reads', 'sequels', 'visuals', 'answer', 'replaced', 'mature', 'cannot', 'wes', 'kilmer', 'fighter', 'marshall', 'indiana', 'delight', 'stone', 'cuba', 'see film', 'advice', 'more time', 'reveals', 'reading', 'client', 'gross', 'master', 'shame', 'film festival', 'enjoyable', 'black cauldron', 'eight', 'sympathy', 'film just', 'many people', 'wahlberg', 'hitchcock', 'refuses', 'fifth', 'imagery', 'sort', 'max', 'nearby', 'abandoned', 'episodes', 'guest', 'high school', 'alien', 'terry']\n",
      "\n",
      "[('but', 1334), ('one', 1247), ('film', 1231), ('not', 1170), ('all', 1117), ('movie', 1095), ('out', 1080), ('so', 1047), ('there', 1046), ('like', 1043)]\n"
     ]
    }
   ],
   "source": [
    "vocab, df, ngram_counts = get_vocab(train_text1, n=3, keep_topN=5000, stop_words=stop_words)\n",
    "print(len(vocab))\n",
    "print()\n",
    "print(list(vocab)[:50])\n",
    "print()\n",
    "print(Counter(df).most_common()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you need to create vocabulary id -> word and id -> word dictionaries for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_id = {i:list(vocab)[i] for i in range(len(vocab))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should be able to extract n-grams for each text in the training, development and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:40.213253Z",
     "start_time": "2020-02-15T14:17:39.329147Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_test, df_test, ngram_counts_test = get_vocab(test_text1, n=3, keep_topN=5000, stop_words=stop_words)\n",
    "vocab_dev, df_dev, ngram_counts_dev = get_vocab(dev_text1, n=3, keep_topN=5000, stop_words=stop_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorise documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write a function `vectoriser` to obtain Bag-of-ngram representations for a list of documents. The function should take as input:\n",
    "- `X_ngram`: a list of texts (documents), where each text is represented as list of n-grams in the `vocab`\n",
    "- `vocab`: a set of n-grams to be used for representing the documents\n",
    "\n",
    "and return:\n",
    "- `X_vec`: an array with dimensionality Nx|vocab| where N is the number of documents and |vocab| is the size of the vocabulary. Each element of the array should represent the frequency of a given n-gram in a document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:40.219201Z",
     "start_time": "2020-02-15T14:17:40.215129Z"
    }
   },
   "outputs": [],
   "source": [
    "# First create function that returns X_ngram\n",
    "\n",
    "def extract_X_ngram(data):\n",
    "    X_ngram = []\n",
    "    for text in data:\n",
    "        ngrams = list(extract_ngrams(text, stop_words=stop_words))\n",
    "        X_ngram.append(ngrams)\n",
    "    return X_ngram\n",
    "\n",
    "def vectorise(X_ngram, vocab):\n",
    "    X_vec = np.zeros([len(X_ngram), len(vocab)])\n",
    "    i=0    \n",
    "    for doc in X_ngram:\n",
    "        doc_counter = Counter(doc)\n",
    "        for id, ngram in vocab_id.items():\n",
    "            X_vec[i][id] = doc_counter[ngram] \n",
    "        i+=1\n",
    "    return X_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use `vectorise` to obtain document vectors for each document in the train, development and test set. You should extract both count and tf.idf vectors respectively:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = extract_X_ngram(train_text1)\n",
    "X_tr_count = vectorise(X_tr, vocab)\n",
    "\n",
    "X_test = extract_X_ngram(test_text1)\n",
    "X_test_count = vectorise(X_test, vocab)\n",
    "\n",
    "X_dev = extract_X_ngram(dev_text1)\n",
    "X_dev_count = vectorise(X_dev, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF.IDF vectors\n",
    "\n",
    "First compute `idfs` an array containing inverted document frequencies (Note: its elements should correspond to your `vocab`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:42.022692Z",
     "start_time": "2020-02-15T14:17:42.012315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the idf values for each word by iterating over document frequencies\n",
    "\n",
    "df_counts = list(df.values())\n",
    "\n",
    "idf = [log(len(X_tr)/i) for i in df_counts]\n",
    "idf_test = [log(len(X_test)/i) for i in df_counts]\n",
    "idf_dev = [log(len(X_dev)/i) for i in df_counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then transform your count vectors to tf.idf vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:42.802265Z",
     "start_time": "2020-02-15T14:17:42.752448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Populate each row of the tfidf array by using the count array multiplied by the appropriate idf value\n",
    "\n",
    "X_tr_tfidf = np.zeros(X_tr_count.shape)\n",
    "X_test_tfidf = np.zeros(X_test_count.shape)\n",
    "X_dev_tfidf = np.zeros(X_dev_count.shape)\n",
    "\n",
    "for i in range(len(X_tr_count)):\n",
    "    X_tr_tfidf[i] = X_tr_count[i]*idf\n",
    "    \n",
    "for i in range(len(X_test_count)):\n",
    "    X_test_tfidf[i] = X_test_count[i]*idf_test\n",
    "    \n",
    "for i in range(len(X_dev_count)):\n",
    "    X_dev_tfidf[i] = X_dev_count[i]*idf_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Logistic Regression\n",
    "\n",
    "After obtaining vector representations of the data, now you are ready to implement Binary Logistic Regression for classifying sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to implement the `sigmoid` function. It takes as input:\n",
    "\n",
    "- `z`: a real number or an array of real numbers \n",
    "\n",
    "and returns:\n",
    "\n",
    "- `sig`: the sigmoid of `z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:44.160661Z",
     "start_time": "2020-02-15T14:17:44.157902Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sig = 1 / (1 + np.exp(-z))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:44.351292Z",
     "start_time": "2020-02-15T14:17:44.346822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[0.00669285 0.76852478]\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid(0)) \n",
    "print(sigmoid(np.array([-5., 1.2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, implement the `predict_proba` function to obtain prediction probabilities. It takes as input:\n",
    "\n",
    "- `X`: an array of inputs, i.e. documents represented by bag-of-ngram vectors ($N \\times |vocab|$)\n",
    "- `weights`: a 1-D array of the model's weights $(1, |vocab|)$\n",
    "\n",
    "and returns:\n",
    "\n",
    "- `preds_proba`: the prediction probabilities of X given the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:44.718566Z",
     "start_time": "2020-02-15T14:17:44.715017Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_proba(X, weights):\n",
    "    z = np.dot(X, weights)\n",
    "    preds_proba = sigmoid(z)\n",
    "    return preds_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in X_tr_count: print(Counter(i), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, implement the `predict_class` function to obtain the most probable class for each vector in an array of input vectors. It takes as input:\n",
    "\n",
    "- `X`: an array of documents represented by bag-of-ngram vectors ($N \\times |vocab|$)\n",
    "- `weights`: a 1-D array of the model's weights $(1, |vocab|)$\n",
    "\n",
    "and returns:\n",
    "\n",
    "- `preds_class`: the predicted class for each x in X given the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:45.002125Z",
     "start_time": "2020-02-15T14:17:44.998668Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_class(X, weights):\n",
    "    probs = predict_proba(X, weights)\n",
    "    preds_class = [round(i+1e-15) for i in probs]\n",
    "    return np.array(preds_class)\n",
    "\n",
    "# round(i+1e-15) is used since the built in round function rounds 0.5 down to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn the weights from data, we need to minimise the binary cross-entropy loss. Implement `binary_loss` that takes as input:\n",
    "\n",
    "- `X`: input vectors\n",
    "- `Y`: labels\n",
    "- `weights`: model weights\n",
    "- `alpha`: regularisation strength\n",
    "\n",
    "and return:\n",
    "\n",
    "- `l`: the loss score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:45.455533Z",
     "start_time": "2020-02-15T14:17:45.451475Z"
    }
   },
   "outputs": [],
   "source": [
    "def binary_loss(X, Y, weights, alpha=0.00001):\n",
    "    m = len(Y) # to average\n",
    "    pred = predict_proba(X, weights)\n",
    "    \n",
    "    class1 = np.dot(Y, np.log(pred + alpha)) # 0 when y = 0\n",
    "    class2 = np.dot(1-Y, np.log(1-pred + alpha)) # 0 when y = 1\n",
    "    \n",
    "    l = -np.sum(class1 + class2)/m\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can implement Stochastic Gradient Descent to learn the weights of your sentiment classifier. The `SGD` function takes as input:\n",
    "\n",
    "- `X_tr`: array of training data (vectors)\n",
    "- `Y_tr`: labels of `X_tr`\n",
    "- `X_dev`: array of development (i.e. validation) data (vectors)\n",
    "- `Y_dev`: labels of `X_dev`\n",
    "- `lr`: learning rate\n",
    "- `alpha`: regularisation strength\n",
    "- `epochs`: number of full passes over the training data\n",
    "- `tolerance`: stop training if the difference between the current and previous validation loss is smaller than a threshold\n",
    "- `print_progress`: flag for printing the training progress (train/validation loss)\n",
    "\n",
    "\n",
    "and returns:\n",
    "\n",
    "- `weights`: the weights learned\n",
    "- `training_loss_history`: an array with the average losses of the whole training set after each epoch\n",
    "- `validation_loss_history`: an array with the average losses of the whole development set after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:45.968510Z",
     "start_time": "2020-02-15T14:17:45.958185Z"
    }
   },
   "outputs": [],
   "source": [
    "def SGD(X_tr, Y_tr, X_dev=[], Y_dev=[], lr=0.1, alpha=0.00001, epochs=5, tolerance=0.0001, print_progress=True):\n",
    "    \n",
    "    training_loss_history = []\n",
    "    validation_loss_history = []\n",
    "    w = np.zeros(X_tr[0].shape)\n",
    "    \n",
    "    # Parallel iteration of X and Y\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle X, y and vocab using same permutation\n",
    "        perm = np.random.permutation(len(Y_tr))\n",
    "        X_tr, Y_tr = X_tr[perm], Y_tr[perm]\n",
    "        for row, label in zip(X_tr, Y_tr):\n",
    "            pred = predict_proba(row, w)\n",
    "            dl_dw = row*(pred - label) + 2*alpha*w\n",
    "            w -= lr*dl_dw\n",
    "            l = binary_loss(X_tr, Y_tr, w, alpha)\n",
    "            l_val = binary_loss(X_dev, Y_dev, w, alpha)\n",
    "        training_loss_history.append(l)\n",
    "        validation_loss_history.append(l_val)\n",
    "        \n",
    "        if print_progress == True:\n",
    "            print('Epoch {0} | Train loss: {1:3f} | Val loss: {2:3f}'.format(epoch+1, l, l_val))\n",
    "\n",
    "        if epoch > 0 and (validation_loss_history[epoch-1] - validation_loss_history[epoch]) < tolerance:\n",
    "             break\n",
    "\n",
    "    return w, training_loss_history, validation_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Logistic Regression with Count vectors\n",
    "\n",
    "First train the model using SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:51.480197Z",
     "start_time": "2020-02-15T14:17:46.362729Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_count, loss_tr_count, loss_dev_count = SGD(X_tr_count, Y_tr, X_dev=X_dev_count, Y_dev=Y_dev,\n",
    "                                            lr=0.0001, alpha=0.001, epochs=100, print_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the training and validation history per epoch. Does your model underfit, overfit or is it about right? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x244bd7922e8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = len(loss_tr_count)\n",
    "plt.plot(list(range(epochs)), loss_tr_count, label = 'Training loss')\n",
    "plt.plot(list(range(epochs)), loss_dev_count, label = 'Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "My model overfits since it fails to generalise to the validation set. We know this because the predictions made for the training data are significantly more accurate than the validation data, which is visualised on the plot. The validation loss curve appears to flatten whilst the training loss continues to fall after each epoch. The regularisation parameter was increased to try and combat this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute accuracy, precision, recall and F1-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_count = predict_class(X_test_count, w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:37:40.569499Z",
     "start_time": "2020-02-15T14:37:40.566796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8325\n",
      "Precision: 0.824390243902439\n",
      "Recall: 0.845\n",
      "F1-Score: 0.8345679012345678\n"
     ]
    }
   ],
   "source": [
    "# fill in your code...\n",
    "print('Accuracy:', accuracy_score(Y_test,preds_test_count))\n",
    "print('Precision:', precision_score(Y_test,preds_test_count))\n",
    "print('Recall:', recall_score(Y_test,preds_test_count))\n",
    "print('F1-Score:', f1_score(Y_test,preds_test_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, print the top-10 words for the negative and positive class respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movies',\n",
       " 'world',\n",
       " 'both',\n",
       " 'also',\n",
       " 'many',\n",
       " 'fun',\n",
       " 'great',\n",
       " 'seen',\n",
       " 'well',\n",
       " 'life']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_index = np.argpartition(w_count, -10)[-10:]\n",
    "top10pos = [vocab_id[i] for i in pos_index]\n",
    "top10pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:37:08.381103Z",
     "start_time": "2020-02-15T14:37:08.378641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'boring',\n",
       " 'only',\n",
       " 'script',\n",
       " 'bad',\n",
       " 'unfortunately',\n",
       " 'why',\n",
       " 'any',\n",
       " 'plot',\n",
       " 'nothing']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_index = np.argpartition(w_count, 10)[:10]\n",
    "top10neg = [vocab_id[i] for i in neg_index]   \n",
    "top10neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we were to apply the classifier we've learned into a different domain such laptop reviews or restaurant reviews, do you think these features would generalise well? Can you propose what features the classifier could pick up as important in the new domain?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All ngrams expressing objective sentiment would be useful as features to classify a review. For example 'great', 'boring' and 'fun'. These words would work in a different domain. Words like 'many', where the sentiment is contextual or subjective would not generalise to different domains very well. For example, 'only' Windows 7 for a laptop would be classified as negative but a 'only' 1 corking fee at the restaurant would be classified as positive. For that reason, if we used the same features for a different domain I don't think it would generalise as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Logistic Regression with TF.IDF vectors\n",
    "\n",
    "Follow the same steps as above (i.e. evaluating count n-gram representations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:17:54.414637Z",
     "start_time": "2020-02-15T14:17:51.625934Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train loss: 0.612224 | Val loss: 0.661897\n",
      "Epoch 2 | Train loss: 0.563750 | Val loss: 0.640820\n",
      "Epoch 3 | Train loss: 0.527255 | Val loss: 0.628350\n",
      "Epoch 4 | Train loss: 0.497606 | Val loss: 0.615468\n",
      "Epoch 5 | Train loss: 0.473010 | Val loss: 0.603989\n",
      "Epoch 6 | Train loss: 0.453124 | Val loss: 0.595426\n",
      "Epoch 7 | Train loss: 0.435796 | Val loss: 0.587308\n",
      "Epoch 8 | Train loss: 0.420905 | Val loss: 0.579911\n",
      "Epoch 9 | Train loss: 0.407370 | Val loss: 0.575017\n",
      "Epoch 10 | Train loss: 0.395020 | Val loss: 0.569094\n",
      "Epoch 11 | Train loss: 0.383862 | Val loss: 0.563073\n",
      "Epoch 12 | Train loss: 0.373840 | Val loss: 0.559188\n",
      "Epoch 13 | Train loss: 0.364423 | Val loss: 0.553462\n",
      "Epoch 14 | Train loss: 0.357258 | Val loss: 0.552199\n",
      "Epoch 15 | Train loss: 0.347605 | Val loss: 0.546967\n",
      "Epoch 16 | Train loss: 0.341592 | Val loss: 0.541707\n",
      "Epoch 17 | Train loss: 0.332685 | Val loss: 0.538888\n",
      "Epoch 18 | Train loss: 0.325831 | Val loss: 0.535682\n",
      "Epoch 19 | Train loss: 0.319733 | Val loss: 0.532460\n",
      "Epoch 20 | Train loss: 0.313283 | Val loss: 0.530288\n",
      "Epoch 21 | Train loss: 0.308580 | Val loss: 0.526581\n",
      "Epoch 22 | Train loss: 0.302012 | Val loss: 0.524559\n",
      "Epoch 23 | Train loss: 0.297592 | Val loss: 0.523747\n",
      "Epoch 24 | Train loss: 0.291751 | Val loss: 0.519790\n",
      "Epoch 25 | Train loss: 0.287079 | Val loss: 0.517343\n",
      "Epoch 26 | Train loss: 0.282429 | Val loss: 0.515224\n",
      "Epoch 27 | Train loss: 0.278051 | Val loss: 0.513865\n",
      "Epoch 28 | Train loss: 0.273930 | Val loss: 0.510778\n",
      "Epoch 29 | Train loss: 0.269721 | Val loss: 0.508955\n",
      "Epoch 30 | Train loss: 0.265620 | Val loss: 0.507550\n",
      "Epoch 31 | Train loss: 0.262013 | Val loss: 0.505313\n",
      "Epoch 32 | Train loss: 0.258196 | Val loss: 0.504396\n",
      "Epoch 33 | Train loss: 0.254623 | Val loss: 0.502694\n",
      "Epoch 34 | Train loss: 0.251472 | Val loss: 0.501611\n",
      "Epoch 35 | Train loss: 0.249627 | Val loss: 0.498598\n",
      "Epoch 36 | Train loss: 0.244577 | Val loss: 0.497760\n",
      "Epoch 37 | Train loss: 0.241682 | Val loss: 0.495838\n",
      "Epoch 38 | Train loss: 0.238416 | Val loss: 0.494766\n",
      "Epoch 39 | Train loss: 0.235503 | Val loss: 0.493655\n",
      "Epoch 40 | Train loss: 0.233175 | Val loss: 0.493089\n",
      "Epoch 41 | Train loss: 0.230036 | Val loss: 0.490526\n",
      "Epoch 42 | Train loss: 0.227125 | Val loss: 0.489539\n",
      "Epoch 43 | Train loss: 0.224521 | Val loss: 0.488495\n",
      "Epoch 44 | Train loss: 0.222073 | Val loss: 0.486832\n",
      "Epoch 45 | Train loss: 0.219773 | Val loss: 0.485637\n",
      "Epoch 46 | Train loss: 0.217108 | Val loss: 0.485216\n",
      "Epoch 47 | Train loss: 0.214649 | Val loss: 0.483635\n",
      "Epoch 48 | Train loss: 0.212321 | Val loss: 0.482677\n",
      "Epoch 49 | Train loss: 0.211296 | Val loss: 0.481400\n",
      "Epoch 50 | Train loss: 0.207876 | Val loss: 0.480508\n",
      "Epoch 51 | Train loss: 0.205784 | Val loss: 0.479883\n",
      "Epoch 52 | Train loss: 0.203625 | Val loss: 0.478730\n",
      "Epoch 53 | Train loss: 0.201555 | Val loss: 0.477759\n",
      "Epoch 54 | Train loss: 0.199793 | Val loss: 0.476511\n",
      "Epoch 55 | Train loss: 0.197786 | Val loss: 0.475608\n",
      "Epoch 56 | Train loss: 0.195764 | Val loss: 0.475241\n",
      "Epoch 57 | Train loss: 0.193844 | Val loss: 0.473965\n",
      "Epoch 58 | Train loss: 0.192001 | Val loss: 0.473152\n",
      "Epoch 59 | Train loss: 0.190790 | Val loss: 0.472238\n",
      "Epoch 60 | Train loss: 0.188429 | Val loss: 0.471544\n",
      "Epoch 61 | Train loss: 0.186648 | Val loss: 0.470796\n",
      "Epoch 62 | Train loss: 0.184949 | Val loss: 0.469976\n",
      "Epoch 63 | Train loss: 0.183327 | Val loss: 0.469514\n",
      "Epoch 64 | Train loss: 0.181990 | Val loss: 0.469138\n",
      "Epoch 65 | Train loss: 0.180055 | Val loss: 0.467786\n",
      "Epoch 66 | Train loss: 0.178596 | Val loss: 0.467376\n",
      "Epoch 67 | Train loss: 0.176950 | Val loss: 0.466341\n",
      "Epoch 68 | Train loss: 0.175560 | Val loss: 0.465989\n",
      "Epoch 69 | Train loss: 0.174355 | Val loss: 0.464875\n",
      "Epoch 70 | Train loss: 0.172782 | Val loss: 0.464791\n",
      "Epoch 71 | Train loss: 0.171285 | Val loss: 0.463998\n",
      "Epoch 72 | Train loss: 0.169881 | Val loss: 0.462864\n",
      "Epoch 73 | Train loss: 0.168362 | Val loss: 0.462598\n",
      "Epoch 74 | Train loss: 0.166953 | Val loss: 0.461716\n",
      "Epoch 75 | Train loss: 0.165748 | Val loss: 0.461455\n",
      "Epoch 76 | Train loss: 0.164481 | Val loss: 0.460908\n",
      "Epoch 77 | Train loss: 0.163049 | Val loss: 0.459906\n",
      "Epoch 78 | Train loss: 0.162567 | Val loss: 0.459445\n",
      "Epoch 79 | Train loss: 0.160552 | Val loss: 0.458989\n",
      "Epoch 80 | Train loss: 0.159323 | Val loss: 0.458419\n"
     ]
    }
   ],
   "source": [
    "w_tfidf, loss_tr_tfidf, loss_dev_tfidf = SGD(X_tr_tfidf, Y_tr, \n",
    "                         X_dev=X_dev_tfidf, \n",
    "                         Y_dev=Y_dev, \n",
    "                         lr=0.00001, \n",
    "                         alpha=0.00001,\n",
    "                         epochs=80, tolerance=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the training and validation history per epoch. Does your model underfit, overfit or is it about right? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x244c2d8b2e8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = len(loss_tr_tfidf)\n",
    "plt.plot(list(range(epochs)), loss_tr_tfidf, label = 'Training loss')\n",
    "plt.plot(list(range(epochs)), loss_dev_tfidf, label = 'Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute accuracy, precision, recall and F1-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:37:56.489814Z",
     "start_time": "2020-02-15T14:37:56.487014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8275\n",
      "Precision: 0.8164251207729468\n",
      "Recall: 0.845\n",
      "F1-Score: 0.8304668304668306\n"
     ]
    }
   ],
   "source": [
    "preds_test_tfidf = predict_class(X_test_tfidf, w_tfidf)\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_test,preds_test_tfidf))\n",
    "print('Precision:', precision_score(Y_test,preds_test_tfidf))\n",
    "print('Recall:', recall_score(Y_test,preds_test_tfidf))\n",
    "print('F1-Score:', f1_score(Y_test,preds_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print top-10 most positive and negative words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:38:17.845485Z",
     "start_time": "2020-02-15T14:38:17.842557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quite',\n",
       " 'world',\n",
       " 'life',\n",
       " 'many',\n",
       " 'also',\n",
       " 'seen',\n",
       " 'both',\n",
       " 'fun',\n",
       " 'well',\n",
       " 'great']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_index_tfidf = np.argpartition(w_tfidf, -10)[-10:]\n",
    "top10pos_tfidf = [vocab_id[i] for i in pos_index_tfidf]\n",
    "top10pos_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:38:22.781128Z",
     "start_time": "2020-02-15T14:38:22.778590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'boring',\n",
       " 'only',\n",
       " 'script',\n",
       " 'bad',\n",
       " 'unfortunately',\n",
       " 'why',\n",
       " 'any',\n",
       " 'plot',\n",
       " 'nothing']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_index_tfidf = np.argpartition(w_tfidf, 10)[:10]\n",
    "top10neg_tfidf = [vocab_id[i] for i in neg_index]   \n",
    "top10neg_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss how did you choose model hyperparameters (e.g. learning rate and regularisation strength)? What is the relation between training epochs and learning rate? How the regularisation strength affects performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TFIDF\n",
    "lr=0.00001, alpha=0.00001, epochs=80\n",
    "\n",
    "- Low learning rate to prevent the model from learning too much in one epoch, which results in a loss increase.\n",
    "- Low regularisation parameter because tfidf regularises the data more than count already.\n",
    "- 80 epochs because the tolerance is reached in much fewer.\n",
    "\n",
    "##### Count\n",
    "lr=0.0001, alpha=0.001, epochs=100\n",
    "\n",
    "- Increased regularisation to generalise to validation set.\n",
    "- Increase learning rate to speed up training.\n",
    "- Default 100 epochs due to time constraints.\n",
    "\n",
    "\n",
    "An increased learning rate means we can do less epochs. If epochs = 10 and lr = 1, we can achieve same effect with epochs = 5 and lr = 2. A larger regularisation strength can close the gap between training loss and validation loss. A large difference between these two losses is indicative of a model that overfits. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Full Results\n",
    "\n",
    "Add here your results:\n",
    "\n",
    "| LR | Precision  | Recall  | F1-Score  |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| BOW-count  |  0.824 | 0.845  | 0.835  |\n",
    "| BOW-tfidf  |  0.856 | 0.775  | 0.814  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Logistic Regression \n",
    "\n",
    "Now you need to train a Multiclass Logistic Regression (MLR) Classifier by extending the Binary model you developed above. You will use the MLR model to perform topic classification on the AG news dataset consisting of three classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Class 1: World\n",
    "- Class 2: Sports\n",
    "- Class 3: Business\n",
    "\n",
    "train: 2,400. 800 per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to follow the same process as in Task 1 for data processing and feature extraction by reusing the functions you wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:18:04.508938Z",
     "start_time": "2020-02-15T14:18:04.171071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "\n",
      "['paid', 'new homes', 'before', 'Minister Alexander', 'KINGSTON', 'Adam Nelson', 'States over', 'thousands', 'investors put', 'Price', 'Minister Tony', 'retailer Tuesday', 'today after', 'Palestinian prisoners', 'bought beaten down', 'challenges', 'PARIS Reuters', 'political', 'qualifying Olympic', 'even more', 'eased fears', 'Tuesday showed', 'Likud party', 'Michael', 'bases', 'BHP Billiton', 'Diego Padres', 'Brian Ching', 'linked', 'previous', 'Tuesday allowed investors', 'soldier killed', 'slumping', 'thrown', 'walk', 'Reuters New', 'States men', 'murder British backpacker', 'Walker', 'MW', 'second half', 'WASHINGTON Reuters', 'boy', 'renegade Afghan', 'cost', 'Al Maktoum', 'Costas Kenteris', 'suspended', 'land', 'Republican', 'Reuters American', 'Mac', 'defending champion', 'hellip', 'November', 'wife', 'Wholesale', 'judges', 'initial stock', 'Jays', 'report showing', 'Tomas Berdych Czech', 'highly anticipated', 'watch', 'defused bomb near', 'order', 'Wal Mart Stores', 'medals', 'regarding', 'ever', 'Conference', 'fullquote gt HD', 'twice', 'threatened', 'quarterly earnings jumped', 'radical Shi ite', 'Houston Astros', 'bell Tuesday after', 'others', 'senior al', 'bell', 'heat', 'Greece top', 'par', 'sixth', 'seeded', 'wider', 'PUNTA', 'landslides', 'after company', 'capture', 'agreed', 'preseason', 'upset', 'sick', 'launch', 'crude oil', 'closer', 'Monday reported percent', 'blow']\n",
      "\n",
      "[('Reuters', 630), ('said', 432), ('Tuesday', 413), ('Wednesday', 344), ('after', 277), ('AP', 275), ('Monday', 221), ('first', 205), ('ATHENS', 194), ('over', 185)]\n"
     ]
    }
   ],
   "source": [
    "vocab2, df2, ngram_counts = get_vocab(train_text2, n=3, keep_topN=5000, stop_words=stop_words)\n",
    "print(len(vocab2))\n",
    "print()\n",
    "print(list(vocab2)[:100])\n",
    "print()\n",
    "print(Counter(df2).most_common()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_id2 = {i:list(vocab2)[i] for i in range(len(vocab2))}\n",
    "\n",
    "X_tr2 = extract_X_ngram(train_text2)\n",
    "X_tr_count2 = vectorise(X_tr2, vocab2)\n",
    "\n",
    "X_test2 = extract_X_ngram(test_text2)\n",
    "X_test_count2 = vectorise(X_test2, vocab2)\n",
    "\n",
    "X_dev2 = extract_X_ngram(dev_text2)\n",
    "X_dev_count2 = vectorise(X_dev2, vocab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count2tfidf(df, X):\n",
    "    \n",
    "    X_tfidf = np.zeros(X.shape)\n",
    "    df_counts = list(df.values())\n",
    "    idf = [log(len(X_tr)/i) for i in df_counts]\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        X_tfidf[i] = X[i]*idf\n",
    "        \n",
    "    return X_tfidf\n",
    "\n",
    "X_tr_tfidf2 = count2tfidf(df2, X_tr_count2)\n",
    "X_test_tfidf2 = count2tfidf(df2, X_test_count2)\n",
    "X_dev_tfidf2 = count2tfidf(df2, X_dev_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to change `SGD` to support multiclass datasets. First you need to develop a `softmax` function. It takes as input:\n",
    "\n",
    "- `z`: array of real numbers \n",
    "\n",
    "and returns:\n",
    "\n",
    "- `smax`: the softmax of `z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:18:07.440998Z",
     "start_time": "2020-02-15T14:18:07.437915Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    e_z = np.exp(z.T)\n",
    "    smax = e_z/sum(e_z)\n",
    "    return smax.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then modify `predict_proba` and `predict_class` functions for the multiclass case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:18:07.445451Z",
     "start_time": "2020-02-15T14:18:07.442851Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_proba2(X, w):\n",
    "    preds_proba = []\n",
    "    z = np.dot(X, w)\n",
    "    if len(z) == 3:\n",
    "        preds_proba = softmax(z)\n",
    "    else:\n",
    "        for row in z:\n",
    "            preds_proba.append(softmax(row))\n",
    "    preds_proba = np.array(preds_proba)\n",
    "    return preds_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:18:07.449814Z",
     "start_time": "2020-02-15T14:18:07.447145Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_class2(X, weights):\n",
    "    \n",
    "    probs = predict_proba2(X, weights)\n",
    "    preds_class = [i.argmax()+1 for i in probs]\n",
    "    \n",
    "    return preds_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy example and expected functionality of the functions above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:18:08.059902Z",
     "start_time": "2020-02-15T14:18:08.056774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [0.1 0.2]\n",
      "1 [0.2 0.1]\n",
      "1 [ 0.1 -0.2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2400, 5000)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0.1,0.2],\n",
    "              [0.2,0.1],\n",
    "              [0.1,-0.2]])\n",
    "w = np.array([[2,-5],\n",
    "              [-5,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:18:08.495464Z",
     "start_time": "2020-02-15T14:18:08.491074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33181223, 0.66818777],\n",
       "       [0.66818777, 0.33181223],\n",
       "       [0.89090318, 0.10909682]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba2(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`array([[0.33181223, 0.66818777],\n",
    "       [0.66818777, 0.33181223],\n",
    "       [0.89090318, 0.10909682]])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:18:08.714215Z",
     "start_time": "2020-02-15T14:18:08.710098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [0.33181223 0.66818777]\n",
      "1 [0.66818777 0.33181223]\n",
      "1 [0.89090318 0.10909682]\n"
     ]
    }
   ],
   "source": [
    "predict_class2(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`array([2, 1, 1])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to compute the categorical cross entropy loss (extending the binary loss to support multiple classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:30:48.047338Z",
     "start_time": "2020-02-15T14:30:48.044395Z"
    }
   },
   "outputs": [],
   "source": [
    "def categorical_loss(X, Y, weights, num_classes=3, alpha=0.00001):\n",
    "    m = len(Y)\n",
    "    pred = predict_proba2(X, weights.T)\n",
    "    pred = np.log(pred + alpha)\n",
    "    y_c = []\n",
    "    \n",
    "    for i in range(int(num_classes)):\n",
    "        y = list((Y == i+1).astype(int))\n",
    "        y_c.append(y)\n",
    "    \n",
    "    y_c = np.array(y_c)    \n",
    "    l = (-1/m)*np.sum(y_c.T * pred)\n",
    "    # - log likelihood of the true class. y = 0 or 1. c = 1, 2 or 3\n",
    "\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:08:59.937442Z",
     "start_time": "2020-02-15T14:08:59.932221Z"
    }
   },
   "source": [
    "Finally you need to modify SGD to support the categorical cross entropy loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD2(X_tr, Y_tr, X_dev=[], Y_dev=[], num_classes=3, lr=0.01, alpha=0.00001, epochs=5, tolerance=0.0001, print_progress=True):\n",
    "    \n",
    "    training_loss_history = []\n",
    "    validation_loss_history = []\n",
    "    w = np.zeros((num_classes, len(X_tr.T)))\n",
    "    \n",
    "    # Parallel iteration of X and Y\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle X, y and vocab using same permutation\n",
    "        perm = np.random.permutation(len(Y_tr))\n",
    "        X_tr, Y_tr = X_tr[perm], Y_tr[perm]\n",
    "        for row, label in zip(X_tr, Y_tr):\n",
    "            for i in range(num_classes):\n",
    "                if label == i+1:\n",
    "                    pred = predict_proba2(row, w.T)\n",
    "                    #print(pred.shape, pred)\n",
    "                    dl_dw = pred[i]*row - row + 2*alpha*w[i]\n",
    "                    w[i] -= lr*dl_dw\n",
    "        l = categorical_loss(X_tr, Y_tr, w, num_classes, alpha)\n",
    "        l_val = categorical_loss(X_dev, Y_dev, w, num_classes, alpha)\n",
    "        training_loss_history.append(l)\n",
    "        validation_loss_history.append(l_val)\n",
    "        \n",
    "        if print_progress == True:\n",
    "            print('Epoch {0} | Train loss: {1:3f} | Val loss: {2:3f}'.format(epoch+1, l, l_val))\n",
    "\n",
    "        if epoch > 0 and (validation_loss_history[epoch-1] - validation_loss_history[epoch]) < tolerance:\n",
    "             break\n",
    "    return w, training_loss_history, validation_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:10:15.772383Z",
     "start_time": "2020-02-15T14:10:15.767855Z"
    }
   },
   "source": [
    "Now you are ready to train and evaluate you MLR following the same steps as in Task 1 for both Count and tfidf features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:18:55.324956Z",
     "start_time": "2020-02-15T14:18:11.720952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train loss: 1.049852 | Val loss: 1.060291\n",
      "Epoch 2 | Train loss: 1.009147 | Val loss: 1.028520\n",
      "Epoch 3 | Train loss: 0.972977 | Val loss: 0.999973\n",
      "Epoch 4 | Train loss: 0.940728 | Val loss: 0.974255\n",
      "Epoch 5 | Train loss: 0.911848 | Val loss: 0.951030\n",
      "Epoch 6 | Train loss: 0.885885 | Val loss: 0.930009\n",
      "Epoch 7 | Train loss: 0.862429 | Val loss: 0.910921\n",
      "Epoch 8 | Train loss: 0.841166 | Val loss: 0.893555\n",
      "Epoch 9 | Train loss: 0.821770 | Val loss: 0.877692\n",
      "Epoch 10 | Train loss: 0.804029 | Val loss: 0.863155\n",
      "Epoch 11 | Train loss: 0.787723 | Val loss: 0.849818\n",
      "Epoch 12 | Train loss: 0.772670 | Val loss: 0.837536\n",
      "Epoch 13 | Train loss: 0.758732 | Val loss: 0.826204\n",
      "Epoch 14 | Train loss: 0.745785 | Val loss: 0.815710\n",
      "Epoch 15 | Train loss: 0.733719 | Val loss: 0.805978\n",
      "Epoch 16 | Train loss: 0.722443 | Val loss: 0.796935\n",
      "Epoch 17 | Train loss: 0.711876 | Val loss: 0.788506\n",
      "Epoch 18 | Train loss: 0.701941 | Val loss: 0.780635\n",
      "Epoch 19 | Train loss: 0.692583 | Val loss: 0.773269\n",
      "Epoch 20 | Train loss: 0.683750 | Val loss: 0.766370\n",
      "Epoch 21 | Train loss: 0.675393 | Val loss: 0.759896\n",
      "Epoch 22 | Train loss: 0.667470 | Val loss: 0.753797\n",
      "Epoch 23 | Train loss: 0.659949 | Val loss: 0.748057\n",
      "Epoch 24 | Train loss: 0.652796 | Val loss: 0.742649\n",
      "Epoch 25 | Train loss: 0.645977 | Val loss: 0.737532\n",
      "Epoch 26 | Train loss: 0.639471 | Val loss: 0.732691\n",
      "Epoch 27 | Train loss: 0.633254 | Val loss: 0.728109\n",
      "Epoch 28 | Train loss: 0.627298 | Val loss: 0.723755\n",
      "Epoch 29 | Train loss: 0.621587 | Val loss: 0.719618\n",
      "Epoch 30 | Train loss: 0.616111 | Val loss: 0.715688\n",
      "Epoch 31 | Train loss: 0.610847 | Val loss: 0.711945\n",
      "Epoch 32 | Train loss: 0.605787 | Val loss: 0.708382\n",
      "Epoch 33 | Train loss: 0.600914 | Val loss: 0.704985\n",
      "Epoch 34 | Train loss: 0.596218 | Val loss: 0.701746\n",
      "Epoch 35 | Train loss: 0.591687 | Val loss: 0.698651\n",
      "Epoch 36 | Train loss: 0.587307 | Val loss: 0.695682\n",
      "Epoch 37 | Train loss: 0.583073 | Val loss: 0.692840\n",
      "Epoch 38 | Train loss: 0.578979 | Val loss: 0.690122\n",
      "Epoch 39 | Train loss: 0.575015 | Val loss: 0.687516\n",
      "Epoch 40 | Train loss: 0.571174 | Val loss: 0.685016\n",
      "Epoch 41 | Train loss: 0.567450 | Val loss: 0.682619\n",
      "Epoch 42 | Train loss: 0.563835 | Val loss: 0.680312\n",
      "Epoch 43 | Train loss: 0.560324 | Val loss: 0.678089\n",
      "Epoch 44 | Train loss: 0.556909 | Val loss: 0.675945\n",
      "Epoch 45 | Train loss: 0.553593 | Val loss: 0.673891\n",
      "Epoch 46 | Train loss: 0.550365 | Val loss: 0.671912\n",
      "Epoch 47 | Train loss: 0.547227 | Val loss: 0.670014\n",
      "Epoch 48 | Train loss: 0.544165 | Val loss: 0.668170\n",
      "Epoch 49 | Train loss: 0.541187 | Val loss: 0.666404\n",
      "Epoch 50 | Train loss: 0.538283 | Val loss: 0.664702\n",
      "Epoch 51 | Train loss: 0.535447 | Val loss: 0.663048\n",
      "Epoch 52 | Train loss: 0.532679 | Val loss: 0.661455\n",
      "Epoch 53 | Train loss: 0.529976 | Val loss: 0.659913\n",
      "Epoch 54 | Train loss: 0.527335 | Val loss: 0.658420\n",
      "Epoch 55 | Train loss: 0.524753 | Val loss: 0.656972\n",
      "Epoch 56 | Train loss: 0.522229 | Val loss: 0.655575\n",
      "Epoch 57 | Train loss: 0.519762 | Val loss: 0.654226\n",
      "Epoch 58 | Train loss: 0.517348 | Val loss: 0.652920\n",
      "Epoch 59 | Train loss: 0.514985 | Val loss: 0.651656\n",
      "Epoch 60 | Train loss: 0.512671 | Val loss: 0.650426\n",
      "Epoch 61 | Train loss: 0.510402 | Val loss: 0.649229\n",
      "Epoch 62 | Train loss: 0.508182 | Val loss: 0.648076\n",
      "Epoch 63 | Train loss: 0.506006 | Val loss: 0.646960\n",
      "Epoch 64 | Train loss: 0.503869 | Val loss: 0.645867\n",
      "Epoch 65 | Train loss: 0.501773 | Val loss: 0.644806\n",
      "Epoch 66 | Train loss: 0.499717 | Val loss: 0.643778\n",
      "Epoch 67 | Train loss: 0.497699 | Val loss: 0.642774\n",
      "Epoch 68 | Train loss: 0.495719 | Val loss: 0.641803\n",
      "Epoch 69 | Train loss: 0.493776 | Val loss: 0.640863\n",
      "Epoch 70 | Train loss: 0.491866 | Val loss: 0.639946\n",
      "Epoch 71 | Train loss: 0.489991 | Val loss: 0.639057\n",
      "Epoch 72 | Train loss: 0.488149 | Val loss: 0.638194\n",
      "Epoch 73 | Train loss: 0.486335 | Val loss: 0.637346\n",
      "Epoch 74 | Train loss: 0.484553 | Val loss: 0.636525\n",
      "Epoch 75 | Train loss: 0.482801 | Val loss: 0.635725\n",
      "Epoch 76 | Train loss: 0.481078 | Val loss: 0.634946\n",
      "Epoch 77 | Train loss: 0.479382 | Val loss: 0.634188\n",
      "Epoch 78 | Train loss: 0.477717 | Val loss: 0.633458\n",
      "Epoch 79 | Train loss: 0.476076 | Val loss: 0.632745\n",
      "Epoch 80 | Train loss: 0.474460 | Val loss: 0.632046\n",
      "Epoch 81 | Train loss: 0.472869 | Val loss: 0.631367\n",
      "Epoch 82 | Train loss: 0.471302 | Val loss: 0.630701\n",
      "Epoch 83 | Train loss: 0.469759 | Val loss: 0.630053\n",
      "Epoch 84 | Train loss: 0.468237 | Val loss: 0.629415\n",
      "Epoch 85 | Train loss: 0.466740 | Val loss: 0.628803\n",
      "Epoch 86 | Train loss: 0.465263 | Val loss: 0.628199\n",
      "Epoch 87 | Train loss: 0.463808 | Val loss: 0.627614\n",
      "Epoch 88 | Train loss: 0.462376 | Val loss: 0.627046\n",
      "Epoch 89 | Train loss: 0.460960 | Val loss: 0.626485\n",
      "Epoch 90 | Train loss: 0.459566 | Val loss: 0.625941\n",
      "Epoch 91 | Train loss: 0.458192 | Val loss: 0.625413\n",
      "Epoch 92 | Train loss: 0.456835 | Val loss: 0.624894\n",
      "Epoch 93 | Train loss: 0.455498 | Val loss: 0.624388\n",
      "Epoch 94 | Train loss: 0.454176 | Val loss: 0.623891\n",
      "Epoch 95 | Train loss: 0.452872 | Val loss: 0.623406\n",
      "Epoch 96 | Train loss: 0.451584 | Val loss: 0.622930\n",
      "Epoch 97 | Train loss: 0.450313 | Val loss: 0.622463\n",
      "Epoch 98 | Train loss: 0.449058 | Val loss: 0.622008\n",
      "Epoch 99 | Train loss: 0.447820 | Val loss: 0.621570\n",
      "Epoch 100 | Train loss: 0.446598 | Val loss: 0.621140\n",
      "Epoch 101 | Train loss: 0.445390 | Val loss: 0.620716\n",
      "Epoch 102 | Train loss: 0.444197 | Val loss: 0.620300\n",
      "Epoch 103 | Train loss: 0.443019 | Val loss: 0.619897\n",
      "Epoch 104 | Train loss: 0.441857 | Val loss: 0.619507\n",
      "Epoch 105 | Train loss: 0.440706 | Val loss: 0.619119\n",
      "Epoch 106 | Train loss: 0.439570 | Val loss: 0.618745\n",
      "Epoch 107 | Train loss: 0.438450 | Val loss: 0.618386\n",
      "Epoch 108 | Train loss: 0.437340 | Val loss: 0.618024\n",
      "Epoch 109 | Train loss: 0.436240 | Val loss: 0.617662\n",
      "Epoch 110 | Train loss: 0.435154 | Val loss: 0.617315\n",
      "Epoch 111 | Train loss: 0.434080 | Val loss: 0.616972\n",
      "Epoch 112 | Train loss: 0.433021 | Val loss: 0.616647\n",
      "Epoch 113 | Train loss: 0.431973 | Val loss: 0.616324\n",
      "Epoch 114 | Train loss: 0.430936 | Val loss: 0.616006\n",
      "Epoch 115 | Train loss: 0.429912 | Val loss: 0.615703\n",
      "Epoch 116 | Train loss: 0.428898 | Val loss: 0.615402\n",
      "Epoch 117 | Train loss: 0.427896 | Val loss: 0.615108\n",
      "Epoch 118 | Train loss: 0.426902 | Val loss: 0.614816\n",
      "Epoch 119 | Train loss: 0.425919 | Val loss: 0.614531\n",
      "Epoch 120 | Train loss: 0.424945 | Val loss: 0.614246\n",
      "Epoch 121 | Train loss: 0.423983 | Val loss: 0.613974\n",
      "Epoch 122 | Train loss: 0.423030 | Val loss: 0.613702\n",
      "Epoch 123 | Train loss: 0.422087 | Val loss: 0.613440\n",
      "Epoch 124 | Train loss: 0.421156 | Val loss: 0.613190\n",
      "Epoch 125 | Train loss: 0.420231 | Val loss: 0.612935\n",
      "Epoch 126 | Train loss: 0.419320 | Val loss: 0.612697\n",
      "Epoch 127 | Train loss: 0.418414 | Val loss: 0.612455\n",
      "Epoch 128 | Train loss: 0.417519 | Val loss: 0.612223\n",
      "Epoch 129 | Train loss: 0.416629 | Val loss: 0.611986\n",
      "Epoch 130 | Train loss: 0.415752 | Val loss: 0.611763\n",
      "Epoch 131 | Train loss: 0.414881 | Val loss: 0.611540\n",
      "Epoch 132 | Train loss: 0.414020 | Val loss: 0.611323\n",
      "Epoch 133 | Train loss: 0.413169 | Val loss: 0.611118\n",
      "Epoch 134 | Train loss: 0.412324 | Val loss: 0.610912\n",
      "Epoch 135 | Train loss: 0.411487 | Val loss: 0.610707\n",
      "Epoch 136 | Train loss: 0.410659 | Val loss: 0.610515\n",
      "Epoch 137 | Train loss: 0.409836 | Val loss: 0.610319\n",
      "Epoch 138 | Train loss: 0.409023 | Val loss: 0.610133\n",
      "Epoch 139 | Train loss: 0.408218 | Val loss: 0.609950\n",
      "Epoch 140 | Train loss: 0.407421 | Val loss: 0.609775\n",
      "Epoch 141 | Train loss: 0.406627 | Val loss: 0.609590\n",
      "Epoch 142 | Train loss: 0.405843 | Val loss: 0.609416\n",
      "Epoch 143 | Train loss: 0.405067 | Val loss: 0.609250\n",
      "Epoch 144 | Train loss: 0.404296 | Val loss: 0.609083\n",
      "Epoch 145 | Train loss: 0.403533 | Val loss: 0.608922\n",
      "Epoch 146 | Train loss: 0.402775 | Val loss: 0.608760\n",
      "Epoch 147 | Train loss: 0.402024 | Val loss: 0.608602\n",
      "Epoch 148 | Train loss: 0.401281 | Val loss: 0.608450\n",
      "Epoch 149 | Train loss: 0.400544 | Val loss: 0.608302\n",
      "Epoch 150 | Train loss: 0.399813 | Val loss: 0.608154\n",
      "Epoch 151 | Train loss: 0.399090 | Val loss: 0.608016\n",
      "Epoch 152 | Train loss: 0.398372 | Val loss: 0.607879\n",
      "Epoch 153 | Train loss: 0.397660 | Val loss: 0.607744\n",
      "Epoch 154 | Train loss: 0.396954 | Val loss: 0.607613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 | Train loss: 0.396254 | Val loss: 0.607483\n",
      "Epoch 156 | Train loss: 0.395561 | Val loss: 0.607364\n",
      "Epoch 157 | Train loss: 0.394873 | Val loss: 0.607239\n",
      "Epoch 158 | Train loss: 0.394192 | Val loss: 0.607122\n",
      "Epoch 159 | Train loss: 0.393514 | Val loss: 0.607002\n",
      "Epoch 160 | Train loss: 0.392842 | Val loss: 0.606886\n",
      "Epoch 161 | Train loss: 0.392174 | Val loss: 0.606769\n",
      "Epoch 162 | Train loss: 0.391513 | Val loss: 0.606656\n",
      "Epoch 163 | Train loss: 0.390857 | Val loss: 0.606546\n",
      "Epoch 164 | Train loss: 0.390206 | Val loss: 0.606436\n",
      "Epoch 165 | Train loss: 0.389559 | Val loss: 0.606328\n",
      "Epoch 166 | Train loss: 0.388916 | Val loss: 0.606218\n",
      "Epoch 167 | Train loss: 0.388282 | Val loss: 0.606121\n"
     ]
    }
   ],
   "source": [
    "#Count\n",
    "w_count, loss_tr_count, dev_loss_count = SGD2(X_tr_count2, Y_tr2, \n",
    "                                             X_dev=X_dev_count2, \n",
    "                                             Y_dev=Y_dev2,\n",
    "                                             num_classes=3,\n",
    "                                             lr=0.001, \n",
    "                                             alpha=0.001, \n",
    "                                             epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train loss: 1.049834 | Val loss: 1.060275\n",
      "Epoch 2 | Train loss: 1.009151 | Val loss: 1.028529\n",
      "Epoch 3 | Train loss: 0.972994 | Val loss: 0.999985\n",
      "Epoch 4 | Train loss: 0.940741 | Val loss: 0.974290\n",
      "Epoch 5 | Train loss: 0.911870 | Val loss: 0.951080\n",
      "Epoch 6 | Train loss: 0.885915 | Val loss: 0.930060\n",
      "Epoch 7 | Train loss: 0.862483 | Val loss: 0.910991\n",
      "Epoch 8 | Train loss: 0.841209 | Val loss: 0.893627\n",
      "Epoch 9 | Train loss: 0.821811 | Val loss: 0.877756\n",
      "Epoch 10 | Train loss: 0.804066 | Val loss: 0.863223\n",
      "Epoch 11 | Train loss: 0.787756 | Val loss: 0.849885\n",
      "Epoch 12 | Train loss: 0.772708 | Val loss: 0.837608\n",
      "Epoch 13 | Train loss: 0.758772 | Val loss: 0.826268\n",
      "Epoch 14 | Train loss: 0.745823 | Val loss: 0.815769\n",
      "Epoch 15 | Train loss: 0.733758 | Val loss: 0.806034\n",
      "Epoch 16 | Train loss: 0.722477 | Val loss: 0.796985\n",
      "Epoch 17 | Train loss: 0.711910 | Val loss: 0.788564\n",
      "Epoch 18 | Train loss: 0.701974 | Val loss: 0.780692\n",
      "Epoch 19 | Train loss: 0.692612 | Val loss: 0.773326\n",
      "Epoch 20 | Train loss: 0.683777 | Val loss: 0.766422\n",
      "Epoch 21 | Train loss: 0.675419 | Val loss: 0.759941\n",
      "Epoch 22 | Train loss: 0.667501 | Val loss: 0.753851\n",
      "Epoch 23 | Train loss: 0.659976 | Val loss: 0.748108\n",
      "Epoch 24 | Train loss: 0.652819 | Val loss: 0.742695\n",
      "Epoch 25 | Train loss: 0.645999 | Val loss: 0.737574\n",
      "Epoch 26 | Train loss: 0.639489 | Val loss: 0.732727\n",
      "Epoch 27 | Train loss: 0.633267 | Val loss: 0.728141\n",
      "Epoch 28 | Train loss: 0.627313 | Val loss: 0.723792\n",
      "Epoch 29 | Train loss: 0.621608 | Val loss: 0.719662\n",
      "Epoch 30 | Train loss: 0.616129 | Val loss: 0.715728\n",
      "Epoch 31 | Train loss: 0.610866 | Val loss: 0.711990\n",
      "Epoch 32 | Train loss: 0.605805 | Val loss: 0.708429\n",
      "Epoch 33 | Train loss: 0.600932 | Val loss: 0.705031\n",
      "Epoch 34 | Train loss: 0.596232 | Val loss: 0.701785\n",
      "Epoch 35 | Train loss: 0.591699 | Val loss: 0.698689\n",
      "Epoch 36 | Train loss: 0.587319 | Val loss: 0.695722\n",
      "Epoch 37 | Train loss: 0.583086 | Val loss: 0.692880\n",
      "Epoch 38 | Train loss: 0.578993 | Val loss: 0.690162\n",
      "Epoch 39 | Train loss: 0.575028 | Val loss: 0.687549\n",
      "Epoch 40 | Train loss: 0.571185 | Val loss: 0.685044\n",
      "Epoch 41 | Train loss: 0.567462 | Val loss: 0.682651\n",
      "Epoch 42 | Train loss: 0.563845 | Val loss: 0.680341\n",
      "Epoch 43 | Train loss: 0.560332 | Val loss: 0.678118\n",
      "Epoch 44 | Train loss: 0.556920 | Val loss: 0.675985\n",
      "Epoch 45 | Train loss: 0.553606 | Val loss: 0.673940\n",
      "Epoch 46 | Train loss: 0.550378 | Val loss: 0.671962\n",
      "Epoch 47 | Train loss: 0.547233 | Val loss: 0.670045\n",
      "Epoch 48 | Train loss: 0.544171 | Val loss: 0.668201\n",
      "Epoch 49 | Train loss: 0.541189 | Val loss: 0.666430\n",
      "Epoch 50 | Train loss: 0.538283 | Val loss: 0.664724\n",
      "Epoch 51 | Train loss: 0.535447 | Val loss: 0.663072\n",
      "Epoch 52 | Train loss: 0.532678 | Val loss: 0.661475\n",
      "Epoch 53 | Train loss: 0.529973 | Val loss: 0.659931\n",
      "Epoch 54 | Train loss: 0.527331 | Val loss: 0.658436\n",
      "Epoch 55 | Train loss: 0.524749 | Val loss: 0.656987\n",
      "Epoch 56 | Train loss: 0.522224 | Val loss: 0.655586\n",
      "Epoch 57 | Train loss: 0.519756 | Val loss: 0.654236\n",
      "Epoch 58 | Train loss: 0.517343 | Val loss: 0.652930\n",
      "Epoch 59 | Train loss: 0.514981 | Val loss: 0.651668\n",
      "Epoch 60 | Train loss: 0.512668 | Val loss: 0.650442\n",
      "Epoch 61 | Train loss: 0.510402 | Val loss: 0.649254\n",
      "Epoch 62 | Train loss: 0.508180 | Val loss: 0.648093\n",
      "Epoch 63 | Train loss: 0.506001 | Val loss: 0.646968\n",
      "Epoch 64 | Train loss: 0.503867 | Val loss: 0.645880\n",
      "Epoch 65 | Train loss: 0.501771 | Val loss: 0.644821\n",
      "Epoch 66 | Train loss: 0.499717 | Val loss: 0.643796\n",
      "Epoch 67 | Train loss: 0.497700 | Val loss: 0.642796\n",
      "Epoch 68 | Train loss: 0.495719 | Val loss: 0.641819\n",
      "Epoch 69 | Train loss: 0.493777 | Val loss: 0.640883\n",
      "Epoch 70 | Train loss: 0.491868 | Val loss: 0.639970\n",
      "Epoch 71 | Train loss: 0.489989 | Val loss: 0.639069\n",
      "Epoch 72 | Train loss: 0.488144 | Val loss: 0.638199\n",
      "Epoch 73 | Train loss: 0.486334 | Val loss: 0.637361\n",
      "Epoch 74 | Train loss: 0.484553 | Val loss: 0.636539\n",
      "Epoch 75 | Train loss: 0.482802 | Val loss: 0.635742\n",
      "Epoch 76 | Train loss: 0.481080 | Val loss: 0.634964\n",
      "Epoch 77 | Train loss: 0.479386 | Val loss: 0.634210\n",
      "Epoch 78 | Train loss: 0.477720 | Val loss: 0.633477\n",
      "Epoch 79 | Train loss: 0.476078 | Val loss: 0.632758\n",
      "Epoch 80 | Train loss: 0.474465 | Val loss: 0.632063\n",
      "Epoch 81 | Train loss: 0.472872 | Val loss: 0.631376\n",
      "Epoch 82 | Train loss: 0.471305 | Val loss: 0.630713\n",
      "Epoch 83 | Train loss: 0.469761 | Val loss: 0.630061\n",
      "Epoch 84 | Train loss: 0.468238 | Val loss: 0.629422\n",
      "Epoch 85 | Train loss: 0.466740 | Val loss: 0.628807\n",
      "Epoch 86 | Train loss: 0.465265 | Val loss: 0.628209\n",
      "Epoch 87 | Train loss: 0.463809 | Val loss: 0.627619\n",
      "Epoch 88 | Train loss: 0.462374 | Val loss: 0.627044\n",
      "Epoch 89 | Train loss: 0.460958 | Val loss: 0.626480\n",
      "Epoch 90 | Train loss: 0.459565 | Val loss: 0.625939\n",
      "Epoch 91 | Train loss: 0.458190 | Val loss: 0.625407\n",
      "Epoch 92 | Train loss: 0.456831 | Val loss: 0.624885\n",
      "Epoch 93 | Train loss: 0.455491 | Val loss: 0.624376\n",
      "Epoch 94 | Train loss: 0.454169 | Val loss: 0.623876\n",
      "Epoch 95 | Train loss: 0.452867 | Val loss: 0.623397\n",
      "Epoch 96 | Train loss: 0.451582 | Val loss: 0.622932\n",
      "Epoch 97 | Train loss: 0.450313 | Val loss: 0.622473\n",
      "Epoch 98 | Train loss: 0.449064 | Val loss: 0.622035\n",
      "Epoch 99 | Train loss: 0.447827 | Val loss: 0.621595\n",
      "Epoch 100 | Train loss: 0.446606 | Val loss: 0.621166\n",
      "Epoch 101 | Train loss: 0.445398 | Val loss: 0.620742\n",
      "Epoch 102 | Train loss: 0.444205 | Val loss: 0.620334\n",
      "Epoch 103 | Train loss: 0.443027 | Val loss: 0.619932\n",
      "Epoch 104 | Train loss: 0.441862 | Val loss: 0.619533\n",
      "Epoch 105 | Train loss: 0.440711 | Val loss: 0.619146\n",
      "Epoch 106 | Train loss: 0.439576 | Val loss: 0.618772\n",
      "Epoch 107 | Train loss: 0.438452 | Val loss: 0.618403\n",
      "Epoch 108 | Train loss: 0.437341 | Val loss: 0.618040\n",
      "Epoch 109 | Train loss: 0.436245 | Val loss: 0.617692\n",
      "Epoch 110 | Train loss: 0.435161 | Val loss: 0.617348\n",
      "Epoch 111 | Train loss: 0.434090 | Val loss: 0.617014\n",
      "Epoch 112 | Train loss: 0.433028 | Val loss: 0.616677\n",
      "Epoch 113 | Train loss: 0.431978 | Val loss: 0.616351\n",
      "Epoch 114 | Train loss: 0.430941 | Val loss: 0.616036\n",
      "Epoch 115 | Train loss: 0.429914 | Val loss: 0.615724\n",
      "Epoch 116 | Train loss: 0.428899 | Val loss: 0.615417\n",
      "Epoch 117 | Train loss: 0.427896 | Val loss: 0.615119\n",
      "Epoch 118 | Train loss: 0.426904 | Val loss: 0.614831\n",
      "Epoch 119 | Train loss: 0.425920 | Val loss: 0.614545\n",
      "Epoch 120 | Train loss: 0.424949 | Val loss: 0.614268\n",
      "Epoch 121 | Train loss: 0.423987 | Val loss: 0.613997\n",
      "Epoch 122 | Train loss: 0.423035 | Val loss: 0.613728\n",
      "Epoch 123 | Train loss: 0.422092 | Val loss: 0.613464\n",
      "Epoch 124 | Train loss: 0.421159 | Val loss: 0.613207\n",
      "Epoch 125 | Train loss: 0.420235 | Val loss: 0.612957\n",
      "Epoch 126 | Train loss: 0.419321 | Val loss: 0.612712\n",
      "Epoch 127 | Train loss: 0.418417 | Val loss: 0.612474\n",
      "Epoch 128 | Train loss: 0.417521 | Val loss: 0.612238\n",
      "Epoch 129 | Train loss: 0.416635 | Val loss: 0.612011\n",
      "Epoch 130 | Train loss: 0.415755 | Val loss: 0.611781\n",
      "Epoch 131 | Train loss: 0.414886 | Val loss: 0.611563\n",
      "Epoch 132 | Train loss: 0.414025 | Val loss: 0.611349\n",
      "Epoch 133 | Train loss: 0.413174 | Val loss: 0.611144\n",
      "Epoch 134 | Train loss: 0.412330 | Val loss: 0.610940\n",
      "Epoch 135 | Train loss: 0.411495 | Val loss: 0.610741\n",
      "Epoch 136 | Train loss: 0.410666 | Val loss: 0.610544\n",
      "Epoch 137 | Train loss: 0.409845 | Val loss: 0.610352\n",
      "Epoch 138 | Train loss: 0.409031 | Val loss: 0.610159\n",
      "Epoch 139 | Train loss: 0.408226 | Val loss: 0.609977\n",
      "Epoch 140 | Train loss: 0.407428 | Val loss: 0.609800\n",
      "Epoch 141 | Train loss: 0.406637 | Val loss: 0.609625\n",
      "Epoch 142 | Train loss: 0.405853 | Val loss: 0.609451\n",
      "Epoch 143 | Train loss: 0.405076 | Val loss: 0.609280\n",
      "Epoch 144 | Train loss: 0.404305 | Val loss: 0.609113\n",
      "Epoch 145 | Train loss: 0.403543 | Val loss: 0.608957\n",
      "Epoch 146 | Train loss: 0.402785 | Val loss: 0.608796\n",
      "Epoch 147 | Train loss: 0.402035 | Val loss: 0.608641\n",
      "Epoch 148 | Train loss: 0.401289 | Val loss: 0.608481\n",
      "Epoch 149 | Train loss: 0.400552 | Val loss: 0.608332\n",
      "Epoch 150 | Train loss: 0.399820 | Val loss: 0.608185\n",
      "Epoch 151 | Train loss: 0.399096 | Val loss: 0.608044\n",
      "Epoch 152 | Train loss: 0.398379 | Val loss: 0.607906\n",
      "Epoch 153 | Train loss: 0.397666 | Val loss: 0.607769\n",
      "Epoch 154 | Train loss: 0.396960 | Val loss: 0.607636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 | Train loss: 0.396259 | Val loss: 0.607505\n",
      "Epoch 156 | Train loss: 0.395564 | Val loss: 0.607377\n",
      "Epoch 157 | Train loss: 0.394876 | Val loss: 0.607254\n",
      "Epoch 158 | Train loss: 0.394193 | Val loss: 0.607135\n",
      "Epoch 159 | Train loss: 0.393515 | Val loss: 0.607012\n",
      "Epoch 160 | Train loss: 0.392841 | Val loss: 0.606888\n",
      "Epoch 161 | Train loss: 0.392175 | Val loss: 0.606776\n",
      "Epoch 162 | Train loss: 0.391515 | Val loss: 0.606667\n",
      "Epoch 163 | Train loss: 0.390859 | Val loss: 0.606557\n",
      "Epoch 164 | Train loss: 0.390207 | Val loss: 0.606448\n",
      "Epoch 165 | Train loss: 0.389562 | Val loss: 0.606347\n",
      "Epoch 166 | Train loss: 0.388921 | Val loss: 0.606241\n",
      "Epoch 167 | Train loss: 0.388285 | Val loss: 0.606140\n",
      "Epoch 168 | Train loss: 0.387656 | Val loss: 0.606048\n"
     ]
    }
   ],
   "source": [
    "# TFIDF\n",
    "w_tfidf, loss_tr_tfidf, dev_loss_tfidf = SGD2(X_tr_count2, Y_tr2, \n",
    "                                             X_dev=X_dev_count2, \n",
    "                                             Y_dev=Y_dev2,\n",
    "                                             num_classes=3,\n",
    "                                             lr=0.001, \n",
    "                                             alpha=0.001, \n",
    "                                             epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training and validation process and explain if your model overfit, underfit or is about right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:31:09.903453Z",
     "start_time": "2020-02-15T14:31:09.901360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24481146c50>"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count\n",
    "epochs = len(loss_tr_count)\n",
    "plt.plot(list(range(epochs)), loss_tr_count, label = 'Training loss')\n",
    "plt.plot(list(range(epochs)), dev_loss_count, label = 'Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24481237d68>"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TFIDF\n",
    "epochs = len(loss_tr_tfidf)\n",
    "plt.plot(list(range(epochs)), loss_tr_tfidf, label = 'Training loss')\n",
    "plt.plot(list(range(epochs)), dev_loss_tfidf, label = 'Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History TFIDF')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute accuracy, precision, recall and F1-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:32:12.606498Z",
     "start_time": "2020-02-15T14:32:12.604164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7366666666666667\n",
      "Precision: 0.7453267947258396\n",
      "Recall: 0.7366666666666667\n",
      "F1-Score: 0.7363437588992419\n"
     ]
    }
   ],
   "source": [
    "# Count\n",
    "preds_te = predict_class2(X_test_count2, w_count.T)\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_test2,preds_te))\n",
    "print('Precision:', precision_score(Y_test2,preds_te,average='macro'))\n",
    "print('Recall:', recall_score(Y_test2,preds_te,average='macro'))\n",
    "print('F1-Score:', f1_score(Y_test2,preds_te,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top-10 words for each class respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:32:26.224693Z",
     "start_time": "2020-02-15T14:32:26.221886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['won men',\n",
       " 'homeless',\n",
       " 'Olympic gold medal',\n",
       " 'Real',\n",
       " 'psychological',\n",
       " 'Baghdad',\n",
       " 'time eight',\n",
       " 'playoff Sunday',\n",
       " 'earnings rose',\n",
       " 'charges']"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# politics, sport, business\n",
    "pol_index = np.argpartition(w_count[0], -10)[-10:]\n",
    "top10pol = [vocab_id2[i] for i in pol_index]\n",
    "top10pol\n",
    "w_count[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now evaluate BOW-tfidf..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7388888888888889\n",
      "Precision: 0.7472416351923837\n",
      "Recall: 0.7388888888888889\n",
      "F1-Score: 0.7388514662856366\n"
     ]
    }
   ],
   "source": [
    "# TFIDF\n",
    "\n",
    "preds_te_tfidf = predict_class2(X_test_tfidf2, w_tfidf.T)\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_test2,preds_te_tfidf))\n",
    "print('Precision:', precision_score(Y_test2,preds_te_tfidf,average='macro'))\n",
    "print('Recall:', recall_score(Y_test2,preds_te_tfidf,average='macro'))\n",
    "print('F1-Score:', f1_score(Y_test2,preds_te_tfidf,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss how did you choose model hyperparameters (e.g. learning rate and regularisation strength)? What is the relation between training epochs and learning rate? How the regularisation strength affects performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:16:19.856538Z",
     "start_time": "2020-02-15T14:16:19.852547Z"
    }
   },
   "source": [
    "Hyperparameters were chosen in a similar way to task one, however I was unable to achieve a validation loss I was happy with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T14:16:42.567569Z",
     "start_time": "2020-02-15T14:16:42.562560Z"
    }
   },
   "source": [
    "## Full Results\n",
    "\n",
    "Add here your results:\n",
    "\n",
    "| LR | Precision  | Recall  | F1-Score  |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| BOW-count  | 0.745  |  0.737 |  0.736 |\n",
    "| BOW-tfidf  |  0.747 | 0.739  | 0.739  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
